#!/usr/bin/env python3

"""
run full space-time evolution in heavy-ion collisions:
    -- initial condition (trento3d)
    -- hydro (vhlle)
    -- particlization (frzout)
    -- hadronic afterburner (UrQMD)
"""

from itertools import chain
import subprocess
import numpy as np
import shutil
import h5py
import sys, os

# load libries distributed with hic-osg
sys.path.insert(1, '../lib/python3.5/site-packages/')
import frzout

def run_cmd(*args, **kwargs):
    print(*args, flush=True)
    subprocess.check_call(
        list(chain.from_iterable(a.split() for a in args)),
        **kwargs
    )

def read_text_file(fileName):
    with open(fileName, 'rb') as f:
        return [l.split() for l in f if not l.startswith(b'#')]


def run_initial(nevent, trento_args):
    """
    run initial condition with trento
    input: nevent(int)--total events in this job; trento_args (string)--trento arguments
    output: .dat files in initialDir folder
    """
    initialDir = 'IC'
    run_cmd('./trento3d ', collision_sys, str(nevent), '--beam-energy {} --xy-max {} --xy-step {} --eta-max {} --eta-step {} --output {}'.format(beam_energy, xy_max, ic_dxy, eta_max, ic_deta, initialDir), trento_args)
   
   
def run_hydro(ievent, hydro_args):
    """
    run hydro for ievent in range(nevent)
    input: ievent (int); hydro_args (python dict)--hydro arguments
    output: hypersurface file in freezeout/$ievent/freezeout.dat 
    """
    initialFile = 'IC/{}.dat'.format(ievent)
    eosFile = 'eos/eos_hotQCD.dat'

    # create hydro config file
    fstream = """outputDir freezeout/{}
    icInputFile {}
    eosFile     {}
    eosType     3
    e_crit      {}
    etaS        {}
    etaS_slope  {}
    zetaS       {}
    nx          81
    ny          81
    nz          41
    xmin        -16.0
    xmax        16.0
    ymin        -16.0
    ymax        16.0
    etamin      -8.0
    etamax      8.0
    tau0        0.6
    tauMax      30.0
    dtau        0.1
    icModel     5
    ic_nxy      {}
    ic_neta     {}
    ic_dxy      {}
    ic_deta     {}
    """.format(ievent, initialFile, eosFile, hydro_args.get('eswitch', 0.3),
            hydro_args.get('etaS', 0.08), hydro_args.get('etaS_slope', 0.), hydro_args.get('zetaS', 0.), 
            ic_nxy, ic_neta, ic_dxy, ic_deta)
    configFile = '3D_crossTerms.conf'
    with open(configFile, 'w') as f:
        f.write(fstream)
    f.close() 
       
    run_cmd('./vhlle ', configFile)


def run_afterburner(ievent, hrg):
    """
    particalization + UrQMD afterburner
    input: ievent (int); hrg (HRG class object)
    output: urqmd_inputFile (Results/urqmd_initial${ievent}.dat)
            urqmd_outputFile (Results/urqmd_final${ievent}.dat)
    return: nsamples
    """
    if not os.path.exists('Results/'):
        os.makedirs('Results')
        
    surfaceFile = 'freezeout/{}/freezeout.dat'.format(ievent)
    # now particalize the hypersurface
    if os.stat(surfaceFile).st_size == 0:
        print('empty hypersurface')
        return 0

    urqmd_inputFile = 'Results/urqmd_initial{}.dat'.format(ievent)
    urqmd_outputFile = 'Results/urqmd_final{}.dat'.format(ievent)


    t,x,y,z, dsigmat,dsigmax,dsigmay,dsigmaz, vx,vy,vz = np.loadtxt(surfaceFile).T[:11]
    position_vec = np.array([t, x, y, z]).T
    normal_vec = np.array([dsigmat, dsigmax, dsigmay, dsigmaz]).T
    velocity_vec = np.array([vx, vy, vz]).T

    surface = frzout.Surface(position_vec, normal_vec, velocity_vec)
    minsamples, maxsamples = 1, 100 # reasonable range for nsamples
    minparts = 10**5    # min numbers of particles to be sampled
    nparts = 0  # in order to track total number of sampled particles

    with open(urqmd_inputFile, 'w') as f:
        for nsamples in range(1, maxsamples + 1):
            parts = frzout.sample(surface, hrg)
            if parts.size == 0:
                continue
            nparts += parts.size
            print("# ", parts.size, file = f)
            for p in parts:
                print(p['ID'], *chain(p['x'], p['p']), file = f)
            if nparts >= minparts and nsamples >= minsamples:
                break
    run_cmd('./afterburner ', urqmd_inputFile, urqmd_outputFile)
    return nsamples

def preprocess_data(ievent, nsamples):
    """
    preprocessing data and save in result${jobID}.hdf5 file
    input: ievent (int); nsamples (int) tot.# of oversamples in the hypersurface
    output: processed light/charged hadron data
    """
    urqmd_outputFile = 'Results/urqmd_final{}.dat'.format(ievent)

    resultFile = 'result{}.hdf5'.format(jobID)
    fres = h5py.File(resultFile, 'a')
    group = fres.create_group('event{}'.format(ievent))

    infoFile = 'IC/{}.event.info'.format(ievent)
    with open(infoFile, 'r') as finfo:
        for line in finfo:
            inputline = line.split()
            if len(inputline) == 4:
                group.attrs.create(inputline[1], float(inputline[3]))
            
    ID, charge, pT, phi, y, eta = (
        np.array(col, dtype=dtype) for (col, dtype) in 
        zip(
            zip(*read_text_file(urqmd_outputFile)),
            (2*[int] + 4*[float])
        )
    )
        
    species = [('pion',211), ('kaon', 321), ('proton', 2212)]

    charged = (charge != 0)
    midrapidity = (np.fabs(y) < 0.5)
    cenkey = (np.fabs(eta) < 0.8)

    group.attrs.create('nsamples', nsamples)
    # dNch_deta
    H, bins = np.histogram(eta[charged], range=(-5, 5), bins=50)
    dNch_deta = H/(bins[1] - bins[0]) / nsamples
    dataset_multi = group.create_dataset('dNch_deta', data = dNch_deta)
    dataset_multi.attrs.create('mid_dNch_deta', np.count_nonzero(midrapidity & charged) / nsamples)
    dataset_multi.attrs.create('cen_key', np.count_nonzero(cenkey & charged) / nsamples)

    # integrated flow cumulants
    phi_ALICE = phi[charged & (np.fabs(eta)<0.8) & (pT>0.2) & (pT<5.0)]
    flow_Qn = [np.exp(1j*n*phi_ALICE).sum() for n in range(1,7)]
    dataset_flow = group.create_dataset('integrated_flow', data = flow_Qn)
    dataset_flow.attrs.create('M', np.count_nonzero(phi_ALICE))
    for name, i in species:
        cut = (np.abs(ID) == i) & midrapidity
        N = np.count_nonzero(cut)
        dataset_flow.attrs.create('dNdy-%s'%name, N/nsamples)
        if N == 0:
            mean_pT = 0
        else:
            mean_pT = pT[cut].mean()
        dataset_flow.attrs.create('mean-pT-%s'%name, mean_pT)
        
    # differential flow
    pT_bin = np.linspace(0.2, 5, 25)
    diff_Q2 = []
    diff_Q3 = []
    diff_M = []
    for i in range(len(pT_bin) -1):
        diff_cut = (charged & (np.fabs(eta)<0.8) & (pT>pT_bin[i]) & (pT < pT_bin[i+1]))
        q2 = np.exp(1j*2*phi[diff_cut]).sum()
        q3 = np.exp(1j*3*phi[diff_cut]).sum()
        m_ = np.count_nonzero(phi[diff_cut])
        diff_Q2.append(q2)
        diff_Q3.append(q3)
        diff_M.append(m_)
    dataset_diff_flow = group.create_dataset('differential_flow', data=[diff_Q2,diff_Q3,diff_M])  
    fres.close()
   


nevent = 10
collision_sys = 'p Pb'
beam_energy = 5020
xy_max = 13.05
ic_dxy = 0.1
eta_max = 10.
ic_deta = 0.2
ic_nxy = int(xy_max*2/ic_dxy)
ic_neta = int(eta_max*2/ic_deta) + 1
print(ic_nxy, ic_neta)

### step 1: parse the arguments
if len(sys.argv) == 3:
    with open(sys.argv[1], 'r') as fargs:
        config = dict((i.strip() for i in l.split('=', maxsplit=1)) for l in fargs)
        jobID = int(sys.argv[2])
        if config['hydro_args'] != '':
            config_args = config['hydro_args']
            ivalue = dict()
            for i in config_args.split():
                ivalue[i.split('=')[0]] = i.split('=')[1]
            config['hydro_args'] = ivalue
    fargs.close()
else:
    config = {}
    jobID = 0

print(config.get('trento_args',''))
print(config.get('hydro_args', {}))    
    
def main():
    trento_args = config.get('trento_args', '')
    ### step 2: run initial condition
    run_initial(nevent,trento_args)
    
    ### step 3: run hydro and afterburner and dataprocessing
    hydro_args = config.get('hydro_args', {})
    Tswitch = float(hydro_args.get('Tswitch', 0.154))
    hrg = frzout.HRG(Tswitch, species = 'urqmd', res_width = True)
    eswitch = hrg.energy_density()
    hydro_args['eswitch'] = eswitch
    
    for ievent in range(nevent):
        run_hydro(ievent, hydro_args)
        nsamples = run_afterburner(ievent, hrg)
        if nsamples > 0:
            preprocess_data(ievent, nsamples)

if __name__ == "__main__":
    main()
